{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGiIUxxG_pYE"
      },
      "source": [
        "Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8WMnQpUnMOHJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading data\n",
        "query_product_df = pd.read_csv('/content/drive/MyDrive/digikala_ds_task_query_product.csv')\n",
        "task_products_df = pd.read_csv('/content/drive/MyDrive/digikala_ds_task_products.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLf87FRY_9fo"
      },
      "source": [
        "Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7xhB8NSMh_Z",
        "outputId": "09ffe204-1b75-488b-d51e-7a9f3ee685f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Cleaning\n",
            "q_id                      0\n",
            "d_id                      0\n",
            "relevancy_score_1         0\n",
            "relevancy_score_2     54770\n",
            "category_id               6\n",
            "brand_id                  6\n",
            "price                167501\n",
            "discount                  6\n",
            "target_score              0\n",
            "dtype: int64\n",
            "date            0\n",
            "d_id            0\n",
            "search_view     0\n",
            "search_click    0\n",
            "search_sales    0\n",
            "dtype: int64\n",
            "0\n",
            "After Cleaning\n",
            "q_id                 0\n",
            "d_id                 0\n",
            "relevancy_score_1    0\n",
            "relevancy_score_2    0\n",
            "category_id          0\n",
            "brand_id             0\n",
            "price                0\n",
            "discount             0\n",
            "target_score         0\n",
            "dtype: int64\n",
            "date            0\n",
            "d_id            0\n",
            "search_view     0\n",
            "search_click    0\n",
            "search_sales    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Handling missing values\n",
        "print(\"Before Cleaning\")\n",
        "print(query_product_df.isnull().sum())\n",
        "print(task_products_df.isnull().sum())\n",
        "\n",
        "# Impute missing values for numerical features\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "query_product_df['price'] = imputer.fit_transform(query_product_df[['price']])\n",
        "query_product_df['discount'] = imputer.fit_transform(query_product_df[['discount']])\n",
        "query_product_df['relevancy_score_2'] = imputer.fit_transform(query_product_df[['relevancy_score_2']])\n",
        "\n",
        "\n",
        "# Impute missing values for categorical features\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "query_product_df['category_id'] = categorical_imputer.fit_transform(query_product_df[['category_id']])\n",
        "query_product_df['brand_id'] = categorical_imputer.fit_transform(query_product_df[['brand_id']])\n",
        "\n",
        "task_products_df.fillna(0, inplace=True)\n",
        "\n",
        "# Check for duplicates\n",
        "print(query_product_df.duplicated(subset=['q_id', 'd_id']).sum())\n",
        "# Remove duplicates if any\n",
        "query_product_df.drop_duplicates(subset=['q_id', 'd_id'], inplace=True)\n",
        "\n",
        "print(\"After Cleaning\")\n",
        "print(query_product_df.isnull().sum())\n",
        "print(task_products_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT1V9hEIAJrm"
      },
      "source": [
        "Handling outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n53CTFo5PTag"
      },
      "outputs": [],
      "source": [
        "# Handling outliers using IQR method for price\n",
        "import numpy as np\n",
        "\n",
        "Q1 = query_product_df['price'].quantile(0.25)\n",
        "Q3 = query_product_df['price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "query_product_df['price'] = np.clip(query_product_df['price'], lower_bound, upper_bound)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iloibCmVAN-9"
      },
      "source": [
        "Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I_inPZtGPdkF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalizing numerical features\n",
        "scaler = StandardScaler()\n",
        "query_product_df[['price', 'discount']] = scaler.fit_transform(query_product_df[['price', 'discount']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFT6t3wwASqB"
      },
      "source": [
        "Merging Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-CrlJ2BrPh2J"
      },
      "outputs": [],
      "source": [
        "# Merging datasets\n",
        "df = pd.merge(query_product_df, task_products_df, on='d_id', how='left')\n",
        "df.fillna(0, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh8Y6XlFAagP"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FL9hC4W3PnzV"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering\n",
        "df['click_through_rate'] = df['search_click'] / df['search_view']\n",
        "df['conversion_rate'] = df['search_sales'] / df['search_click']\n",
        "df['effective_price'] = df['price'] * (1 - df['discount'])\n",
        "\n",
        "# Handling division by zero\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# Date conversion\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df['day_of_week'] = df['date'].dt.dayofweek\n",
        "df['days_before_event'] = (pd.to_datetime('2023-12-23') - df['date']).dt.days\n",
        "df = df.drop(columns=['date'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOHcPd4NSSjE",
        "outputId": "fd521773-0007-4878-cb4a-c24a1371d43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytrec_eval\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytrec_eval\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308201 sha256=9ac0d42270985200dcd47d77262aab322f90ae4c233633ee3802d178e9588506\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "Successfully built pytrec_eval\n",
            "Installing collected packages: pytrec_eval\n",
            "Successfully installed pytrec_eval-0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pytrec_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Im0j-HIPkc"
      },
      "source": [
        "Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8TvNZQPeIMX3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "X = df.drop(columns=['target_score'])\n",
        "y = df['target_score']\n",
        "groups = df['q_id']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, test_idx = next(gss.split(X, y, groups))\n",
        "\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv1Yr67QInHq"
      },
      "source": [
        "Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_AriySRImcH",
        "outputId": "00d11052-da3a-49fb-f3eb-76f966567de0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-5e593999bb27>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
            "<ipython-input-8-5e593999bb27>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Replace inf values\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3UANw5RIvk8"
      },
      "source": [
        "Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka-o81HPKddE",
        "outputId": "8b14021b-fbf0-46c7-9815-dd93ed77b2bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial sklearn NDCG Score: 0.9756\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRanker\n",
        "from sklearn.metrics import ndcg_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the group size\n",
        "groups_train_size = groups_train.value_counts().sort_index().values\n",
        "\n",
        "# Define the model\n",
        "model = XGBRanker(objective='rank:pairwise', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, group=groups_train_size)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate using sklearn's NDCG\n",
        "sklearn_ndcg = ndcg_score([y_test], [y_pred])\n",
        "print(f\"Initial sklearn NDCG Score: {sklearn_ndcg:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOnNjrRkbSrT"
      },
      "source": [
        "Handling the error of being negative in y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLOcvXhpSGNS",
        "outputId": "0c33924f-dc9c-4849-a893-2bc760b6391d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in y_train: [4.45000000e-07 6.73000000e-06 7.82000000e-06 ... 1.27272727e+00\n",
            " 1.30000000e+00 1.40697674e+00]\n",
            "Unique values in y_test: [1.28000000e-05 2.04000000e-05 4.35000000e-05 ... 1.23913044e+00\n",
            " 1.26712329e+00 1.30851064e+00]\n",
            "Unique values in corrected y_train: [0 1]\n",
            "Unique values in corrected y_test: [0 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Check unique values\n",
        "print(\"Unique values in y_train:\", np.unique(y_train))\n",
        "print(\"Unique values in y_test:\", np.unique(y_test))\n",
        "\n",
        "# Convert to non-negative integers if necessary\n",
        "if not np.all(np.floor(y_train) == y_train) or np.any(y_train < 0):\n",
        "    y_train = np.floor(y_train).astype(int)\n",
        "\n",
        "if not np.all(np.floor(y_test) == y_test) or np.any(y_test < 0):\n",
        "    y_test = np.floor(y_test).astype(int)\n",
        "\n",
        "# Re-check labels\n",
        "print(\"Unique values in corrected y_train:\", np.unique(y_train))\n",
        "print(\"Unique values in corrected y_test:\", np.unique(y_test))\n",
        "\n",
        "# Ensure non-negative integers\n",
        "def ensure_non_negative_integers(y):\n",
        "    if not np.all(np.floor(y) == y) or np.any(y < 0):\n",
        "        raise ValueError(\"Target labels must be non-negative integers.\")\n",
        "    return y\n",
        "\n",
        "y_train = ensure_non_negative_integers(y_train)\n",
        "y_test = ensure_non_negative_integers(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVJ_o6EzcAuC"
      },
      "source": [
        "Model Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fgPMPv3mQJ5z",
        "outputId": "26dbf04a-1f7d-4c60-dafc-19613e7a2119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-5ac926d1f9e5>:49: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
            "  yield np.where(test_mask)[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=10, reg_lambda=0, subsample=1.0; total time=   5.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:821: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 810, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
            "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "TypeError: group_ndcg_scorer() missing 2 required positional arguments: 'y' and 'groups'\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=10, reg_lambda=0, subsample=1.0; total time=  26.9s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=10, reg_lambda=0, subsample=1.0; total time=  19.0s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=10, reg_lambda=0, subsample=1.0; total time=  17.1s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=10, reg_lambda=0, subsample=1.0; total time=  17.0s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=10, subsample=1.0; total time=   1.5s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=10, subsample=1.0; total time= 1.3min\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=10, subsample=1.0; total time= 1.4min\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=10, subsample=1.0; total time= 1.3min\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=10, subsample=1.0; total time= 1.3min\n",
            "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=100, reg_alpha=1, reg_lambda=0.1, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=100, reg_alpha=1, reg_lambda=0.1, subsample=0.8; total time=  23.4s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=100, reg_alpha=1, reg_lambda=0.1, subsample=0.8; total time=  20.8s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=100, reg_alpha=1, reg_lambda=0.1, subsample=0.8; total time=  23.5s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, min_child_weight=7, n_estimators=100, reg_alpha=1, reg_lambda=0.1, subsample=0.8; total time=  21.1s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=   1.4s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  25.9s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  26.3s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  24.7s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=1, n_estimators=100, reg_alpha=0.1, reg_lambda=0, subsample=1.0; total time=  25.0s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=   1.4s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  37.6s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  34.9s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  35.0s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  37.7s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=   1.4s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  41.9s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  39.0s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  41.3s\n",
            "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=200, reg_alpha=0.1, reg_lambda=0, subsample=0.6; total time=  41.6s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=500, reg_alpha=0.1, reg_lambda=10, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=500, reg_alpha=0.1, reg_lambda=10, subsample=0.8; total time= 1.8min\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=500, reg_alpha=0.1, reg_lambda=10, subsample=0.8; total time= 1.9min\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=500, reg_alpha=0.1, reg_lambda=10, subsample=0.8; total time= 1.8min\n",
            "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=500, reg_alpha=0.1, reg_lambda=10, subsample=0.8; total time= 2.0min\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=200, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=   1.5s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=200, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  44.2s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=200, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  43.7s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=200, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  43.3s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=200, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  43.2s\n",
            "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=300, reg_alpha=10, reg_lambda=1, subsample=0.6; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=300, reg_alpha=10, reg_lambda=1, subsample=0.6; total time=  53.7s\n",
            "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=300, reg_alpha=10, reg_lambda=1, subsample=0.6; total time=  56.1s\n",
            "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=300, reg_alpha=10, reg_lambda=1, subsample=0.6; total time=  56.3s\n",
            "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=300, reg_alpha=10, reg_lambda=1, subsample=0.6; total time=  53.7s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=   1.8s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  23.4s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  22.3s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  23.1s\n",
            "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, min_child_weight=7, n_estimators=100, reg_alpha=0.1, reg_lambda=10, subsample=1.0; total time=  23.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "10 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [21:54:41] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [21:56:03] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:01:24] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:02:54] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:04:37] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:07:04] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:09:49] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:17:21] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:20:17] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 2021, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2100, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 284, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [22:23:58] /workspace/src/data/data.cc:762: Check failed: group_ptr_.back() == num_row_ (859835 vs. 859834) : Invalid query group structure. The number of rows obtained from group doesn't equal to the actual number of rows given by data.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78b53842dbbc]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x4a93e6) [0x78b5386a93e6]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5c30bf) [0x78b5387c30bf]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(+0x5cabc9) [0x78b5387cabc9]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78b53833742f]\n",
            "  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x78b5bfd06e2e]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x78b5bfd03493]\n",
            "  [bt] (7) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x78b5bfd2c3e9]\n",
            "  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x9a00) [0x78b5bfd2ba00]\n",
            "\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 10, 'n_estimators': 100, 'min_child_weight': 7, 'max_depth': 7, 'learning_rate': 0.3, 'gamma': 0.1, 'colsample_bytree': 1.0}\n",
            "Best cross-validation score: nan\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5ac926d1f9e5>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_ndcg_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nNDCG Score on Test Set: {test_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-5ac926d1f9e5>\u001b[0m in \u001b[0;36mgroup_ndcg_scorer\u001b[0;34m(estimator, X, y, groups)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrue_relevance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpredicted_relevance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndcg_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_relevance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredicted_relevance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mndcg_score\u001b[0;34m(y_true, y_score, k, sample_weight, ignore_ties)\u001b[0m\n\u001b[1;32m   1799\u001b[0m     \u001b[0;36m0.5\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \"\"\"\n\u001b[0;32m-> 1801\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1802\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    977\u001b[0m                 \u001b[0;34m\"Found array with %d feature(s) (shape=%s) while\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                 \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required."
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "import numpy as np\n",
        "from sklearn.model_selection._split import _BaseKFold\n",
        "\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 3, 5, 7],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    'reg_alpha': [0, 0.1, 1, 10],\n",
        "    'reg_lambda': [0, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Custom scorer function\n",
        "def group_ndcg_scorer(estimator, X, y, groups):\n",
        "    group_counts = np.bincount(groups)\n",
        "    y_pred = estimator.predict(X)\n",
        "    scores = []\n",
        "    start = 0\n",
        "    for count in group_counts:\n",
        "        end = start + count\n",
        "        true_relevance = y[start:end]\n",
        "        predicted_relevance = y_pred[start:end]\n",
        "        scores.append(ndcg_score([true_relevance], [predicted_relevance]))\n",
        "        start = end\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "# Custom GroupKFold that returns group indices\n",
        "class CustomGroupKFold(_BaseKFold):\n",
        "    def __init__(self, n_splits=5):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "\n",
        "    def _iter_test_indices(self, X, y, groups):\n",
        "        unique_groups = np.unique(groups)\n",
        "        n_groups = len(unique_groups)\n",
        "        group_indices = np.arange(n_groups)\n",
        "\n",
        "        for test_group_indices in np.array_split(group_indices, self.n_splits):\n",
        "            test_groups = unique_groups[test_group_indices]\n",
        "            test_mask = np.isin(groups, test_groups)\n",
        "            yield np.where(test_mask)[0]\n",
        "\n",
        "# Setup RandomizedSearchCV\n",
        "xgb_model = XGBRanker(objective='rank:ndcg', tree_method='hist', random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,\n",
        "    scoring=make_scorer(group_ndcg_scorer, needs_proba=False),\n",
        "    cv=CustomGroupKFold(n_splits=5),\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train_scaled, y_train, group=groups_train_size)\n",
        "\n",
        "\n",
        "# Evaluate results\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "test_score = group_ndcg_scorer(best_model, X_test_scaled, y_test, groups_test)\n",
        "print(f\"\\nNDCG Score on Test Set: {test_score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ez_MziU7xu"
      },
      "source": [
        "Other Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heDZ-hNpUkrJ",
        "outputId": "7f23ab2a-52fa-4856-9d34-f224f23875b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sklearn NDCG Score: 0.9759\n",
            "\n",
            "Sample qrels data:\n",
            "[('30', {'436443': 3, '467566': 3, '440251': 3, '482725': 3, '443321': 3, '481961': 1, '507261': 0, '503474': 0, '486341': 2, '485691': 0, '488426': 0, '499462': 0, '421741': 1, '494500': 2, '514278': 0, '440258': 0, '486335': 1, '498518': 1, '474779': 0, '522065': 0, '440068': 1, '421364': 0, '523715': 0, '482612': 0, '485668': 1, '462131': 2, '505692': 0, '485653': 0, '433378': 2, '523709': 1, '468916': 0, '495080': 2, '487930': 2, '522069': 1, '468914': 1}), ('42', {'396006': 3, '498146': 2, '485120': 2, '412432': 2, '503731': 2, '404735': 1, '298870': 2, '406762': 1, '406702': 1, '447049': 1, '32368': 1, '166241': 1, '18457': 1, '283': 0, '285': 0, '1145': 0, '11914': 1, '5809': 1, '4963': 0, '85193': 0, '444151': 2, '477268': 2, '477269': 0, '102851': 1, '177953': 2, '177957': 2, '416022': 1, '503707': 0, '412392': 0, '147820': 0, '262667': 0, '406339': 0, '421045': 1, '454809': 0, '86962': 1, '865': 0, '32373': 0, '68707': 0, '102759': 1, '102844': 1})]\n",
            "\n",
            "Sample run data:\n",
            "[('30', {'436443': 1.4696271419525146, '467566': -0.7353039383888245, '440251': 1.2362709045410156, '482725': -0.02106661908328533, '443321': 0.3508748710155487, '481961': -1.8483251333236694, '507261': -0.6611153483390808, '503474': -0.7192643284797668, '486341': -0.4909280836582184, '485691': -1.0809180736541748, '488426': -0.8730985522270203, '499462': -0.918973445892334, '421741': -0.8097453713417053, '494500': -0.7888010144233704, '514278': -0.24274542927742004, '440258': 0.3598250150680542, '486335': -1.0062090158462524, '498518': 0.16005931794643402, '474779': -1.7531076669692993, '522065': -1.6793677806854248, '440068': -1.0728331804275513, '421364': -0.6786260604858398, '523715': -1.8218327760696411, '482612': -1.8552484512329102, '485668': -0.03723350539803505, '462131': -0.8302316665649414, '505692': -0.5578930974006653, '485653': 1.0184428691864014, '433378': -0.9480934143066406, '523709': -1.9099276065826416, '468916': -0.5921545028686523, '495080': -0.8388609290122986, '487930': -1.7531076669692993, '522069': -1.8546098470687866, '468914': -0.7701441049575806}), ('42', {'396006': 2.025865077972412, '498146': 0.678524374961853, '485120': 1.1870055198669434, '412432': 0.8232116103172302, '503731': 0.21112778782844543, '404735': -0.1655668020248413, '298870': -2.135324716567993, '406762': -1.157013177871704, '406702': -2.0442264080047607, '447049': -1.9459502696990967, '32368': -2.3030147552490234, '166241': -2.3092501163482666, '18457': -2.3482930660247803, '283': -2.13873553276062, '285': -2.13873553276062, '1145': -2.359984874725342, '11914': -2.13873553276062, '5809': -2.396636962890625, '4963': -2.13873553276062, '85193': -1.3688247203826904, '444151': -2.106067657470703, '477268': -1.8659971952438354, '477269': -1.8659971952438354, '102851': -2.1265769004821777, '177953': -1.4417109489440918, '177957': -2.1294031143188477, '416022': -2.1277408599853516, '503707': 0.7716959714889526, '412392': 0.833739697933197, '147820': -2.060788869857788, '262667': -1.3583176136016846, '406339': -2.121229887008667, '421045': -2.009202480316162, '454809': -0.7483918070793152, '86962': -2.019296169281006, '865': -2.0688083171844482, '32373': -2.3030147552490234, '68707': -2.160611867904663, '102759': -2.389535665512085, '102844': -2.1265769004821777})]\n",
            "\n",
            "Evaluation Metrics:\n",
            "Average MAP: 0.7837\n",
            "Average MRR: 0.9718\n",
            "Average NDCG (pytrec_eval): 0.9016\n",
            "Average Precision@5: 0.9009\n",
            "\n",
            "Top 10 Feature Importance:\n",
            "d_id: 1145.0\n",
            "relevancy_score_1: 767.0\n",
            "price: 645.0\n",
            "search_click: 542.0\n",
            "relevancy_score_2: 474.0\n",
            "category_id: 474.0\n",
            "click_through_rate: 399.0\n",
            "effective_price: 342.0\n",
            "q_id: 299.0\n",
            "brand_id: 265.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRanker\n",
        "from sklearn.metrics import ndcg_score\n",
        "import pytrec_eval\n",
        "\n",
        "\n",
        "# Create group labels based on q_id\n",
        "group_train = X_train.groupby('q_id').size().to_frame('size')['size'].to_numpy()\n",
        "group_test = X_test.groupby('q_id').size().to_frame('size')['size'].to_numpy()\n",
        "\n",
        "# Store q_id and d_id before dropping them\n",
        "q_id_test = X_test['q_id']\n",
        "d_id_test = X_test['d_id']\n",
        "\n",
        "# Train XGBRanker model\n",
        "model = XGBRanker(objective='rank:pairwise', learning_rate=0.1, n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train, group=group_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate using sklearn's NDCG\n",
        "sklearn_ndcg = ndcg_score([y_test], [y_pred])\n",
        "print(f\"sklearn NDCG Score: {sklearn_ndcg:.4f}\")\n",
        "\n",
        "# Prepare data for pytrec_eval\n",
        "qrels = {}\n",
        "run = {}\n",
        "\n",
        "for q_id, d_id, true_score, pred_score in zip(q_id_test, d_id_test, y_test, y_pred):\n",
        "    q_id_str = str(q_id)\n",
        "    d_id_str = str(d_id)\n",
        "\n",
        "    if q_id_str not in qrels:\n",
        "        qrels[q_id_str] = {}\n",
        "        run[q_id_str] = {}\n",
        "\n",
        "    qrels[q_id_str][d_id_str] = int(true_score * 5)  # Scale to 0-5 range and convert to int\n",
        "    run[q_id_str][d_id_str] = float(pred_score)\n",
        "\n",
        "# Print sample data\n",
        "print(\"\\nSample qrels data:\")\n",
        "print(list(qrels.items())[:2])\n",
        "print(\"\\nSample run data:\")\n",
        "print(list(run.items())[:2])\n",
        "\n",
        "# Create evaluator\n",
        "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'map', 'recip_rank', 'ndcg', 'P_5'})\n",
        "\n",
        "# Compute metrics\n",
        "results = evaluator.evaluate(run)\n",
        "\n",
        "# Calculate average scores\n",
        "avg_map = np.mean([query_results['map'] for query_results in results.values()])\n",
        "avg_mrr = np.mean([query_results['recip_rank'] for query_results in results.values()])\n",
        "avg_ndcg = np.mean([query_results['ndcg'] for query_results in results.values()])\n",
        "avg_precision_at_5 = np.mean([query_results['P_5'] for query_results in results.values()])\n",
        "\n",
        "# Print results\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"Average MAP: {avg_map:.4f}\")\n",
        "print(f\"Average MRR: {avg_mrr:.4f}\")\n",
        "print(f\"Average NDCG (pytrec_eval): {avg_ndcg:.4f}\")\n",
        "print(f\"Average Precision@5: {avg_precision_at_5:.4f}\")\n",
        "\n",
        "\n",
        "# Print feature importance\n",
        "feature_importance = model.get_booster().get_score(importance_type='weight')\n",
        "sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nTop 10 Feature Importance:\")\n",
        "for feature, importance in sorted_importance[:10]:\n",
        "    print(f\"{feature}: {importance}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
